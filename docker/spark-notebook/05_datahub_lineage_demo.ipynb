{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DataHub + Iceberg + Spark Lineage Demo\n",
        "\n",
        "This notebook demonstrates the full data platform integration:\n",
        "- **Apache Spark** - Distributed data processing\n",
        "- **Apache Iceberg** - Table format with time travel\n",
        "- **Apache Polaris** - Iceberg REST Catalog\n",
        "- **MinIO** - S3-compatible storage\n",
        "- **DataHub** - Data catalog with lineage tracking\n",
        "\n",
        "## What we'll do:\n",
        "1. Create source tables in Iceberg\n",
        "2. Transform data (generates lineage)\n",
        "3. View the lineage in DataHub\n",
        "4. Run the Polaris ingestion to sync metadata\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup Spark Session\n",
        "\n",
        "Using the pre-configured connector with OpenLineage enabled for DataHub lineage tracking.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from connector import create_spark_session\n",
        "\n",
        "# Create Spark session with Polaris + OpenLineage config\n",
        "spark = create_spark_session(\"datahub-lineage-demo\")\n",
        "print(f\"Spark version: {spark.version}\")\n",
        "print(f\"Available catalogs: {spark.catalog.listCatalogs()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Create Source Data\n",
        "\n",
        "We'll create two source tables that will be joined to produce a derived table.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Switch to the Polaris catalog\n",
        "spark.sql(\"USE polaris\")\n",
        "\n",
        "# Create a demo namespace (database)\n",
        "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS demo\")\n",
        "spark.sql(\"USE demo\")\n",
        "\n",
        "print(\"Created namespace: polaris.demo\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sample customers table\n",
        "customers_data = [\n",
        "    (1, \"Alice\", \"alice@example.com\", \"Copenhagen\"),\n",
        "    (2, \"Bob\", \"bob@example.com\", \"Aarhus\"),\n",
        "    (3, \"Charlie\", \"charlie@example.com\", \"Odense\"),\n",
        "    (4, \"Diana\", \"diana@example.com\", \"Aalborg\"),\n",
        "    (5, \"Erik\", \"erik@example.com\", \"Copenhagen\"),\n",
        "]\n",
        "\n",
        "customers_df = spark.createDataFrame(\n",
        "    customers_data, \n",
        "    [\"customer_id\", \"name\", \"email\", \"city\"]\n",
        ")\n",
        "\n",
        "# Write as Iceberg table\n",
        "customers_df.writeTo(\"polaris.demo.customers\").createOrReplace()\n",
        "print(\"Created table: polaris.demo.customers\")\n",
        "customers_df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sample orders table\n",
        "from datetime import date\n",
        "\n",
        "orders_data = [\n",
        "    (101, 1, date(2024, 1, 15), 150.00, \"completed\"),\n",
        "    (102, 2, date(2024, 1, 16), 250.00, \"completed\"),\n",
        "    (103, 1, date(2024, 1, 17), 75.00, \"completed\"),\n",
        "    (104, 3, date(2024, 1, 18), 300.00, \"pending\"),\n",
        "    (105, 4, date(2024, 1, 19), 125.00, \"completed\"),\n",
        "    (106, 5, date(2024, 1, 20), 450.00, \"completed\"),\n",
        "    (107, 1, date(2024, 1, 21), 200.00, \"cancelled\"),\n",
        "    (108, 2, date(2024, 1, 22), 180.00, \"completed\"),\n",
        "]\n",
        "\n",
        "orders_df = spark.createDataFrame(\n",
        "    orders_data,\n",
        "    [\"order_id\", \"customer_id\", \"order_date\", \"amount\", \"status\"]\n",
        ")\n",
        "\n",
        "# Write as Iceberg table\n",
        "orders_df.writeTo(\"polaris.demo.orders\").createOrReplace()\n",
        "print(\"Created table: polaris.demo.orders\")\n",
        "orders_df.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Transform Data (Generates Lineage)\n",
        "\n",
        "Now we'll create a derived table by joining customers and orders.\n",
        "This transformation generates lineage that DataHub will track.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read source tables\n",
        "customers = spark.table(\"polaris.demo.customers\")\n",
        "orders = spark.table(\"polaris.demo.orders\")\n",
        "\n",
        "# Join and aggregate: Customer order summary\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "customer_summary = (\n",
        "    orders\n",
        "    .filter(F.col(\"status\") == \"completed\")\n",
        "    .groupBy(\"customer_id\")\n",
        "    .agg(\n",
        "        F.count(\"order_id\").alias(\"total_orders\"),\n",
        "        F.sum(\"amount\").alias(\"total_spent\"),\n",
        "        F.avg(\"amount\").alias(\"avg_order_value\"),\n",
        "        F.max(\"order_date\").alias(\"last_order_date\")\n",
        "    )\n",
        "    .join(customers, \"customer_id\")\n",
        "    .select(\n",
        "        \"customer_id\",\n",
        "        \"name\",\n",
        "        \"email\",\n",
        "        \"city\",\n",
        "        \"total_orders\",\n",
        "        \"total_spent\",\n",
        "        \"avg_order_value\",\n",
        "        \"last_order_date\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Write derived table - THIS GENERATES LINEAGE!\n",
        "customer_summary.writeTo(\"polaris.demo.customer_summary\").createOrReplace()\n",
        "print(\"Created derived table: polaris.demo.customer_summary\")\n",
        "print(\"\\nLineage: customers + orders -> customer_summary\")\n",
        "customer_summary.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create another derived table: City-level analytics\n",
        "city_analytics = (\n",
        "    spark.table(\"polaris.demo.customer_summary\")\n",
        "    .groupBy(\"city\")\n",
        "    .agg(\n",
        "        F.count(\"customer_id\").alias(\"customer_count\"),\n",
        "        F.sum(\"total_spent\").alias(\"city_revenue\"),\n",
        "        F.avg(\"avg_order_value\").alias(\"city_avg_order\")\n",
        "    )\n",
        "    .orderBy(F.desc(\"city_revenue\"))\n",
        ")\n",
        "\n",
        "# Write - generates more lineage\n",
        "city_analytics.writeTo(\"polaris.demo.city_analytics\").createOrReplace()\n",
        "print(\"Created derived table: polaris.demo.city_analytics\")\n",
        "print(\"\\nLineage: customer_summary -> city_analytics\")\n",
        "city_analytics.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Verify Tables in Iceberg\n",
        "\n",
        "Let's verify all tables exist in the Polaris catalog.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all tables in the demo namespace\n",
        "print(\"Tables in polaris.demo:\")\n",
        "spark.sql(\"SHOW TABLES IN polaris.demo\").show()\n",
        "\n",
        "# Show table details\n",
        "print(\"\\nCustomers table schema:\")\n",
        "spark.sql(\"DESCRIBE polaris.demo.customers\").show()\n",
        "\n",
        "print(\"\\nIceberg table history (time travel):\")\n",
        "spark.sql(\"SELECT * FROM polaris.demo.customers.history\").show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. View in DataHub\n",
        "\n",
        "Now open DataHub to see the tables and lineage:\n",
        "\n",
        "1. **Access DataHub UI:**\n",
        "   ```bash\n",
        "   kubectl port-forward svc/datahub-datahub-frontend -n datahub 9002:9002\n",
        "   ```\n",
        "   Open: http://localhost:9002\n",
        "\n",
        "2. **Run Polaris ingestion to sync metadata:**\n",
        "   ```bash\n",
        "   kubectl apply -f k8s/datahub/ingestion-configmap.yaml\n",
        "   kubectl delete job datahub-ingest-polaris -n datahub --ignore-not-found\n",
        "   kubectl apply -f k8s/datahub/ingestion-polaris.yaml\n",
        "   ```\n",
        "\n",
        "3. **Navigate to:**\n",
        "   - **Search** for \"customers\", \"orders\", \"customer_summary\"\n",
        "   - **Lineage tab** shows data flow\n",
        "   - **Schema tab** shows columns\n",
        "\n",
        "4. **Expected Lineage Graph:**\n",
        "   ```\n",
        "   customers ─────┐\n",
        "                  ├──> customer_summary ──> city_analytics\n",
        "   orders ────────┘\n",
        "   ```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print summary\n",
        "print(\"=\"*60)\n",
        "print(\"DEMO COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nCreated tables:\")\n",
        "print(\"  - polaris.demo.customers (source)\")\n",
        "print(\"  - polaris.demo.orders (source)\")\n",
        "print(\"  - polaris.demo.customer_summary (derived)\")\n",
        "print(\"  - polaris.demo.city_analytics (derived)\")\n",
        "print(\"\\nLineage generated:\")\n",
        "print(\"  customers + orders -> customer_summary -> city_analytics\")\n",
        "print(\"\\nView in DataHub:\")\n",
        "print(\"  kubectl port-forward svc/datahub-datahub-frontend -n datahub 9002:9002\")\n",
        "print(\"  http://localhost:9002\")\n",
        "print(\"\\nTo sync metadata to DataHub:\")\n",
        "print(\"  kubectl apply -f k8s/datahub/ingestion-polaris.yaml\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stop Spark session\n",
        "spark.stop()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
