---
- name: Bootstrap k3d-based Spark dev cluster with Spark Operator and JupyterHub
  hosts: localhost
  connection: local
  gather_facts: false

  vars:
    # Cluster name for k3d
    k3d_cluster_name: spark-cluster
    spark_operator_release: spark-operator
    spark_operator_namespace: spark-operator
    jupyterhub_release: jhub
    jupyterhub_namespace: jhub-dev
    datahub_release: datahub
    datahub_namespace: datahub

    # Treat this playbook as being inside ansible/playbooks relative to repo root
    repo_root: "{{ playbook_dir }}/../.."

    load_images: false

    # k3d port mappings (host:container@loadbalancer)
    k3d_http_port: "8080:80@loadbalancer"
    k3d_https_port: "8443:443@loadbalancer"
    k3d_agents: 2

    # ============================================
    # Default values for standalone execution
    # When using inventory files, these are overridden
    # ============================================

    # Helm repository configuration (defaults to public internet repos)
    _helm_spark_operator_repo_name: "{{ helm_spark_operator_repo_name | default('spark-operator') }}"
    _helm_spark_operator_repo_url: "{{ helm_spark_operator_repo_url | default('https://kubeflow.github.io/spark-operator') }}"
    _helm_jupyterhub_repo_name: "{{ helm_jupyterhub_repo_name | default('jupyterhub') }}"
    _helm_jupyterhub_repo_url: "{{ helm_jupyterhub_repo_url | default('https://jupyterhub.github.io/helm-chart/') }}"
    _helm_datahub_repo_name: "{{ helm_datahub_repo_name | default('datahub') }}"
    _helm_datahub_repo_url: "{{ helm_datahub_repo_url | default('https://helm.datahubproject.io/') }}"

    # Image configuration (defaults to public Docker Hub)
    _spark_base_image: "{{ spark_base_image | default('statkube/spark-base:spark3.5.3-py3.12-1') }}"
    _spark_notebook_image: "{{ spark_notebook_image | default('statkube/spark-notebook:spark3.5.3-py3.12-1') }}"

  tasks:
    - name: Display environment configuration
      ansible.builtin.debug:
        msg: |
          Environment: {{ environment_name | default('internet (default)') }}
          Cluster Type: k3d (k3s in Docker)
          Spark Operator Helm Repo: {{ _helm_spark_operator_repo_url }}
          JupyterHub Helm Repo: {{ _helm_jupyterhub_repo_url }}
          Spark Base Image: {{ _spark_base_image }}
          Spark Notebook Image: {{ _spark_notebook_image }}
          Port Mappings: {{ k3d_http_port }}, {{ k3d_https_port }}

    - name: Check if k3d cluster already exists
      ansible.builtin.command:
        cmd: "k3d cluster list -o json"
      register: k3d_list
      changed_when: false
      failed_when: false

    - name: Create k3d cluster with port mappings
      ansible.builtin.command:
        cmd: >
          k3d cluster create {{ k3d_cluster_name }}
          --agents {{ k3d_agents }}
          --port {{ k3d_http_port }}
          --port {{ k3d_https_port }}
      register: k3d_create
      when: k3d_cluster_name not in (k3d_list.stdout | default(''))
      failed_when: k3d_create.rc not in [0, 1]
      changed_when: k3d_create.rc == 0

    - name: Use k3d cluster context
      ansible.builtin.command:
        cmd: "kubectl config use-context k3d-{{ k3d_cluster_name }}"

    - name: Optionally load base image into k3d
      ansible.builtin.command:
        cmd: "k3d image import {{ spark_base_image }} -c {{ k3d_cluster_name }}"
      when: load_images | bool

    - name: Optionally load notebook image into k3d
      ansible.builtin.command:
        cmd: "k3d image import {{ spark_notebook_image }} -c {{ k3d_cluster_name }}"
      when: load_images | bool

    - name: Add Spark Operator Helm repo
      ansible.builtin.command:
        cmd: "helm repo add {{ _helm_spark_operator_repo_name }} {{ _helm_spark_operator_repo_url }}"
      register: spark_repo
      changed_when: "'has been added' in spark_repo.stdout"
      failed_when: spark_repo.rc not in [0]

    - name: Add JupyterHub Helm repo
      ansible.builtin.command:
        cmd: "helm repo add {{ _helm_jupyterhub_repo_name }} {{ _helm_jupyterhub_repo_url }}"
      register: jhub_repo
      changed_when: "'has been added' in jhub_repo.stdout"
      failed_when: jhub_repo.rc not in [0]

    - name: Add DataHub Helm repo
      ansible.builtin.command:
        cmd: "helm repo add {{ _helm_datahub_repo_name }} {{ _helm_datahub_repo_url }}"
      register: datahub_repo
      changed_when: "'has been added' in datahub_repo.stdout"
      failed_when: datahub_repo.rc not in [0]

    - name: Update Helm repos
      ansible.builtin.command:
        cmd: "helm repo update"
      register: helm_repo_update
      failed_when: false

    - name: Install or upgrade Spark Operator (dev - internet)
      ansible.builtin.command:
        cmd: >
          helm upgrade --install {{ spark_operator_release }} {{ _helm_spark_operator_repo_name }}/spark-operator
          --version 1.1.27
          --namespace {{ spark_operator_namespace }} --create-namespace
          -f {{ repo_root }}/k8s/spark-operator/values-base.yaml
          -f {{ repo_root }}/k8s/spark-operator/values-dev.yaml
      when: environment_name | default('internet') == 'internet'

    - name: Install or upgrade Spark Operator (dev - onprem)
      ansible.builtin.command:
        cmd: >
          helm upgrade --install {{ spark_operator_release }} {{ _helm_spark_operator_repo_name }}/spark-operator
          --version 1.1.27
          --namespace {{ spark_operator_namespace }} --create-namespace
          -f {{ repo_root }}/k8s/spark-operator/values-base.yaml
          -f {{ repo_root }}/k8s/spark-operator/values-onprem.yaml
          -f {{ repo_root }}/k8s/spark-operator/values-dev.yaml
      when: environment_name | default('internet') == 'onprem'

    - name: Install or upgrade JupyterHub (dev - internet with k3d)
      ansible.builtin.command:
        cmd: >
          helm upgrade --install {{ jupyterhub_release }} {{ _helm_jupyterhub_repo_name }}/jupyterhub
          --namespace {{ jupyterhub_namespace }} --create-namespace
          -f {{ repo_root }}/k8s/jupyterhub/values-base.yaml
          -f {{ repo_root }}/k8s/jupyterhub/values-k3d.yaml
      when: environment_name | default('internet') == 'internet'

    - name: Install or upgrade JupyterHub (dev - onprem with k3d)
      ansible.builtin.command:
        cmd: >
          helm upgrade --install {{ jupyterhub_release }} {{ _helm_jupyterhub_repo_name }}/jupyterhub
          --namespace {{ jupyterhub_namespace }} --create-namespace
          -f {{ repo_root }}/k8s/jupyterhub/values-base.yaml
          -f {{ repo_root }}/k8s/jupyterhub/values-onprem.yaml
          -f {{ repo_root }}/k8s/jupyterhub/values-k3d.yaml
      when: environment_name | default('internet') == 'onprem'

    - name: Create JupyterHub Ingress (routes through Traefik)
      ansible.builtin.command:
        cmd: "kubectl apply -f {{ repo_root }}/k8s/jupyterhub/ingress-k3d.yaml"

    - name: Deploy MinIO (internet)
      ansible.builtin.command:
        cmd: "kubectl apply -f {{ repo_root }}/k8s/minio/minio.yaml"
      when: environment_name | default('internet') == 'internet'

    - name: Deploy MinIO (onprem)
      ansible.builtin.command:
        cmd: "kubectl apply -f {{ repo_root }}/k8s/minio/minio-onprem.yaml"
      when: environment_name | default('internet') == 'onprem'

    - name: Wait for MinIO deployment to be ready
      ansible.builtin.command:
        cmd: "kubectl wait --for=condition=available deployment/minio -n minio --timeout=120s"
      register: minio_wait
      failed_when: false

    - name: Deploy Polaris (internet)
      ansible.builtin.command:
        cmd: "kubectl apply -f {{ repo_root }}/k8s/polaris/polaris.yaml"
      when: environment_name | default('internet') == 'internet'

    - name: Deploy Polaris (onprem)
      ansible.builtin.command:
        cmd: "kubectl apply -f {{ repo_root }}/k8s/polaris/polaris-onprem.yaml"
      when: environment_name | default('internet') == 'onprem'

    - name: Wait for Polaris deployment to be ready
      ansible.builtin.command:
        cmd: "kubectl wait --for=condition=available deployment/polaris -n polaris --timeout=120s"
      register: polaris_wait
      failed_when: false

    - name: Delete existing Polaris bootstrap job (if any)
      ansible.builtin.command:
        cmd: "kubectl delete job polaris-bootstrap-catalog -n polaris --ignore-not-found"

    - name: Bootstrap Polaris S3-backed catalog (internet)
      ansible.builtin.command:
        cmd: "kubectl apply -f {{ repo_root }}/k8s/polaris/polaris-bootstrap.yaml"
      when: environment_name | default('internet') == 'internet'

    - name: Bootstrap Polaris S3-backed catalog (onprem)
      ansible.builtin.command:
        cmd: "kubectl apply -f {{ repo_root }}/k8s/polaris/polaris-bootstrap-onprem.yaml"
      when: environment_name | default('internet') == 'onprem'

    # ============================================
    # DataHub Deployment (Two-Chart Setup)
    # 1. Install prerequisites (MySQL, Elasticsearch, Kafka)
    # 2. Install DataHub services
    # ============================================

    - name: Create DataHub namespace
      ansible.builtin.command:
        cmd: "kubectl create namespace {{ datahub_namespace }}"
      register: create_datahub_ns
      failed_when: create_datahub_ns.rc not in [0, 1]
      changed_when: create_datahub_ns.rc == 0

    - name: Create MySQL secrets for DataHub
      ansible.builtin.command:
        cmd: >
          kubectl create secret generic mysql-secrets
          --from-literal=mysql-root-password=datahub
          --namespace {{ datahub_namespace }}
      register: mysql_secret
      failed_when: mysql_secret.rc not in [0, 1]
      changed_when: mysql_secret.rc == 0

    - name: Install DataHub prerequisites (MySQL, Elasticsearch, Kafka)
      ansible.builtin.command:
        cmd: >
          helm upgrade --install prerequisites {{ _helm_datahub_repo_name }}/datahub-prerequisites
          --namespace {{ datahub_namespace }}
          -f {{ repo_root }}/k8s/datahub/prerequisites-values.yaml
          --timeout 10m
          --wait
      register: datahub_prereq
      failed_when: false

    - name: Display prerequisites status
      ansible.builtin.debug:
        msg: "DataHub prerequisites: {{ 'SUCCESS' if datahub_prereq.rc == 0 else 'FAILED - check with: kubectl get pods -n datahub' }}"

    - name: Wait for Elasticsearch to be ready
      ansible.builtin.command:
        cmd: "kubectl wait --for=condition=ready pod -l app=elasticsearch-master -n {{ datahub_namespace }} --timeout=300s"
      register: es_wait
      failed_when: false
      when: datahub_prereq.rc == 0

    - name: Install DataHub services (dev - internet)
      ansible.builtin.command:
        cmd: >
          helm upgrade --install {{ datahub_release }} {{ _helm_datahub_repo_name }}/datahub
          --namespace {{ datahub_namespace }}
          -f {{ repo_root }}/k8s/datahub/values-base.yaml
          -f {{ repo_root }}/k8s/datahub/values-dev.yaml
          --timeout 15m
          --wait
      when: environment_name | default('internet') == 'internet' and datahub_prereq.rc == 0
      register: datahub_install
      failed_when: false

    - name: Install DataHub services (dev - onprem)
      ansible.builtin.command:
        cmd: >
          helm upgrade --install {{ datahub_release }} {{ _helm_datahub_repo_name }}/datahub
          --namespace {{ datahub_namespace }}
          -f {{ repo_root }}/k8s/datahub/values-base.yaml
          -f {{ repo_root }}/k8s/datahub/values-onprem.yaml
          -f {{ repo_root }}/k8s/datahub/values-dev.yaml
          --timeout 15m
          --wait
      when: environment_name | default('internet') == 'onprem' and datahub_prereq.rc == 0
      register: datahub_install_onprem
      failed_when: false

    - name: Display DataHub installation status
      ansible.builtin.debug:
        msg: |
          DataHub installation status: {{ 'SUCCESS' if (datahub_install.rc | default(datahub_install_onprem.rc | default(1))) == 0 else 'PENDING/FAILED - check pods with: kubectl get pods -n datahub' }}
          Note: DataHub takes 5-10 minutes to fully initialize on first run.

    - name: Wait for DataHub GMS to be ready
      ansible.builtin.command:
        cmd: "kubectl wait --for=condition=available deployment/datahub-datahub-gms -n {{ datahub_namespace }} --timeout=300s"
      register: datahub_gms_wait
      failed_when: false

    - name: Deploy DataHub Polaris ingestion ConfigMap
      ansible.builtin.command:
        cmd: "kubectl apply -f {{ repo_root }}/k8s/datahub/ingestion-configmap.yaml"
      when: datahub_gms_wait.rc | default(1) == 0

    - name: Delete existing DataHub ingestion job (if any)
      ansible.builtin.command:
        cmd: "kubectl delete job datahub-ingest-polaris -n {{ datahub_namespace }} --ignore-not-found"
      when: datahub_gms_wait.rc | default(1) == 0

    - name: Run DataHub Polaris ingestion job (internet)
      ansible.builtin.command:
        cmd: "kubectl apply -f {{ repo_root }}/k8s/datahub/ingestion-polaris.yaml"
      when: environment_name | default('internet') == 'internet' and datahub_gms_wait.rc | default(1) == 0

    - name: Run DataHub Polaris ingestion job (onprem)
      ansible.builtin.command:
        cmd: "kubectl apply -f {{ repo_root }}/k8s/datahub/ingestion-polaris-onprem.yaml"
      when: environment_name | default('internet') == 'onprem' and datahub_gms_wait.rc | default(1) == 0

    - name: Create spark-sa ServiceAccount in jhub-dev
      ansible.builtin.command:
        cmd: "kubectl apply -f {{ repo_root }}/k8s/jupyterhub/service-account.yaml"

    - name: Grant spark-sa access to default namespace
      ansible.builtin.command:
        cmd: "kubectl apply -f {{ repo_root }}/k8s/jupyterhub/spark-rbac.yaml"

    - name: Create spark-sa ServiceAccount in default namespace
      ansible.builtin.command:
        cmd: "kubectl create serviceaccount spark-sa --namespace default"
      register: create_sa_default
      failed_when: create_sa_default.rc not in [0, 1]
      changed_when: create_sa_default.rc == 0

    - name: Display access information
      ansible.builtin.debug:
        msg: |
          âœ… k3d cluster '{{ k3d_cluster_name }}' is ready!
          
          JupyterHub is available at: http://localhost:8080
          Login: any username / password: test
          
          DataHub UI: kubectl port-forward svc/datahub-datahub-frontend -n datahub 9002:9002
          Then open: http://localhost:9002
          Login: datahub / datahub
          
          No port-forward needed for JupyterHub - k3d's built-in LoadBalancer handles it!
          
          Useful commands:
            kubectl get pods -n jhub-dev
            kubectl get pods -n spark-operator
            kubectl get pods -n datahub
            k3d cluster list
            k3d cluster stop {{ k3d_cluster_name }}
            k3d cluster delete {{ k3d_cluster_name }}

